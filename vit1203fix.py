# -*- coding: utf-8 -*-
"""ViT1203fix.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ACdExOLq6NdsceM4hWewtmLDeQx22nbZ

2021/06/21

#Vision Transformer による絵画の作者予測

収蔵品データセットに作品数が20以上含まれる画家を対象として行う

参考：

* [google-researchによるVision Transformerの実装 (Git) ](https://github.com/google-research/vision_transformer)
* [google-researchによるVision Transformerの実装 (Colab) ](https://colab.research.google.com/github/google-research/vision_transformer/blob/master/vit_jax.ipynb#scrollTo=jFqi3h7yMEsB)
* [[TensorFlow チュートリアル] tf.dataを使って画像をロードする](https://www.tensorflow.org/tutorials/load_data/images?hl=ja)
* [google colabでVision TransformerのFine Tuningをやってみた - Qiita](https://qiita.com/kanataken/items/dc579fa0f53b7f84ef25#%E3%83%9F%E3%83%8B%E3%83%90%E3%83%83%E3%83%81%E3%81%AE%E4%BD%9C%E6%88%90)
"""

import pandas as pd
import numpy as np
import numpy.random as random
from pandas import Series, DataFrame

# !git clone https://github.com/obrmmk/ViT_MET_datasets.git

# train_data=pd.read_csv('./ViT_MET_datasets/painting/Artist/twe/painting_twe_train.csv')
# test_data=pd.read_csv('./ViT_MET_datasets/painting/Artist/twe/painting_twe_test.csv')

!git clone https://github.com/d-d-d-mutsumi181/ViT_dataset.git


train_data_tmp=pd.read_csv('./ViT_dataset/Medium/ten/painting_ten_train1.csv')
test_data_tmp=pd.read_csv('./ViT_dataset/Medium/ten/painting_ten_test1.csv')

# train_data_tmp = train_data_tmp[:176]
train_data_tmp.reset_index(inplace=True, drop=True)
train_data_tmp.head()
print(len(train_data_tmp))

![ -d vision_transformer ] || git clone --depth=1 https://github.com/google-research/vision_transformer
!cd vision_transformer && git pull
!pip install -qr vision_transformer/vit_jax/requirements.txt

# Shows all available pre-trained models.
!gsutil ls -lh gs://vit_models/imagenet*
!gsutil ls -lh gs://mixer_models/*

# Download a pre-trained model.

# Note: you can really choose any of the above, but this Colab has been tested
# with the models of below selection...
model_name = 'ViT-L_16'  #@param ["ViT-B_16", "ViT-B_32","ViT-L_16","ViT-L_32","Mixer-B_16","R26+ViT-B_32","R50+ViT-B_16","R50+ViT-L_32"]

if model_name.startswith('ViT'):
  ![ -e "$model_name".npz ] || gsutil cp gs://vit_models/imagenet21k/"$model_name".npz .
if model_name.startswith('Mixer'):
  ![ -e "$model_name".npz ] || gsutil cp gs://mixer_models/imagenet21k/"$model_name".npz .

import os
assert os.path.exists(f'{model_name}.npz')

from absl import logging
import flax
import jax
from matplotlib import pyplot as plt
import numpy as np
import tqdm

logging.set_verbosity(logging.INFO)

# Shows the number of available devices.
# In a CPU/GPU runtime this will be a single device.
# In a TPU runtime this will be 8 cores.
jax.local_devices()

#batch[0].shape[0]

#batch['image']

# Commented out IPython magic to ensure Python compatibility.
# Import files from repository.
# Updating the files in the editor on the right will immediately update the
# modules by re-importing them.

import sys
if './vision_transformer' not in sys.path:
  sys.path.append('./vision_transformer')

# %load_ext autoreload
# %autoreload 2

from vit_jax import checkpoint
from vit_jax import input_pipeline
from vit_jax import utils
from vit_jax import models
from vit_jax import momentum_clip
from vit_jax import train
from vit_jax.configs import common as common_config
from vit_jax.configs import models as models_config

# import tensorflow as tf
# from tensorflow import keras

# AUTOTUNE = tf.data.experimental.AUTOTUNE
# label_names = sorted(list(set([item for item in train_data['Artist Display Name']])))
# label_to_index_pre = dict((index,name) for index,name in enumerate(label_names))
# df = pd.DataFrame.from_dict(label_to_index_pre, orient='index')
# df = df.reset_index()
# df = df.set_axis(['label', 'Artist Display Name'], axis=1)
# all_image_labels=[]
# for i in range(len(train_data)):
#   all_image_labels.append(int(df[df['Artist Display Name'] == train_data.loc[i]['Artist Display Name']]['label']))
# all_image_labels_i = [int(s) for s in all_image_labels]
# n_labels = len(np.unique(all_image_labels_i))

# count=0
# def create_file(url):
#   global count
#   count+=1
#   image = tf.keras.utils.get_file(str(count)+'.jpg', origin=url)
#   return image

# all_image_paths = list(train_data['primaryImage'])
# image_count = len(all_image_paths)

train_data_tmp

test_data_tmp

import requests

all_image_paths = list(train_data_tmp['primaryImage'])
all_image_medium = list(train_data_tmp["Medium"])
paths_tmp= []
medium_tmp = []

cnt = 0
for i in range(len(train_data_tmp)):
  all_image_paths[i] = all_image_paths[i].replace(' ', '%20')
  res = requests.get(all_image_paths[i])
  if res.status_code != 404:
    paths_tmp.append(all_image_paths[i])
    medium_tmp.append(all_image_medium[i])
  else:
    cnt += 1

all_image_paths = paths_tmp
all_image_medium = medium_tmp
    
image_count = len(all_image_paths)
print(image_count, cnt)
print(image_count+cnt)

train_data = pd.DataFrame()
train_data["primaryImage"]  = all_image_paths
train_data["Medium"] = all_image_medium
train_data

import tensorflow as tf
from tensorflow import keras

AUTOTUNE = tf.data.experimental.AUTOTUNE
label_names = sorted(list(set([item for item in train_data['Medium']])))
label_to_index_pre = dict((index,name) for index,name in enumerate(label_names))
df = pd.DataFrame.from_dict(label_to_index_pre, orient='index')
df = df.reset_index()
df = df.set_axis(['label', 'Medium'], axis=1)
all_image_labels=[]
for i in range(len(train_data)):
  all_image_labels.append(int(df[df['Medium'] == train_data.loc[i]['Medium']]['label']))
all_image_labels_i = [int(s) for s in all_image_labels]
n_labels = len(np.unique(all_image_labels_i))

count=0
def create_file(url):
  global count
  count+=1
  image = tf.keras.utils.get_file(str(count)+'.jpg', origin=url)#originalなデータセットのURL
  return image

# all_image_paths = list(train_data['primaryImage'])
# all_image_medium = list(train_data["Medium"])

# #NotFoundを除去するコードを挿入
# memo = []
# for i in range(len(train_data)):
#   all_image_paths[i] = all_image_paths[i].replace(' ', '%20')
#   if all_image_paths[i] == 'https://images.metmuseum.org/CRDImages/ep/original/DP169647.jpg':
#     memo.append(i)
#   elif all_image_paths[i] == 'https://images.metmuseum.org/CRDImages/ep/original/DT236256.jpg':
#     memo.append(i)
# #データがNotFoundだったため消去
# #train_data.drop(memo)


# for i in memo:
#   all_image_paths.pop(memo(i))

# #all_image_paths.pop(*memo)


# image_count = len(all_image_paths)

print(image_count)

all_image_paths

!pip install tqdm
from tqdm.notebook import tqdm

for i in tqdm(all_image_paths):
  create_file(i)

# # 2021年12月3日　私とてるちと時々高野さん
# import requests
# res = requests.get('https://images.metmuseum.org/CRDImages/ep/original/ep07.225.253.bw.R.jpg:')
# print(res.status_code)

import pathlib

data_root = pathlib.Path('/root/.keras/datasets/')
all_image_paths = sorted(list(sorted(data_root.glob('?.jpg'))))+sorted(list(sorted(data_root.glob('??.jpg'))))+sorted(list(sorted(data_root.glob('???.jpg'))))
all_image_paths = [str(path) for path in all_image_paths]
all_image_labels_o = np.eye(n_labels)[all_image_labels_i] 

def preprocess_image(image):
  image = tf.image.decode_jpeg(image, channels=3) #RGBなのでchannels=3
  image = tf.image.resize(image, [384, 384])
  image /= 255.0  #正規化（全てのデータを0～1の間の大きさにする） / 画像処理ではピクセルのRGB値(0~255)が特徴量となる
  return image

def load_and_preprocess_image(path):
  image = tf.io.read_file(path)
  return preprocess_image(image)

path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)
image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)

label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels_o, tf.int64))
image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))

n_labels

#image_dsの確認
plt.figure(figsize=(8,8))
for n,image in enumerate(image_ds.take(4)):
 plt.subplot(2,2,n+1)
 plt.imshow(image)
 plt.grid(False)
 plt.xticks([])
 plt.yticks([])
 plt.show()

image_count

model_config = models_config.MODEL_CONFIGS[model_name]
model_config     #スクショしてね

num_classes=15

BATCH_SIZE = 1789 #1789の約数に変換
ds = image_label_ds.batch(BATCH_SIZE)
# `prefetch`を使うことで、モデルの訓練中にバックグラウンドでデータセットがバッチを取得できます
ds = ds.prefetch(buffer_size=AUTOTUNE) 
batch = next(iter(ds.as_numpy_iterator()))

# モデル定義を読み込み、ランダムなパラメータを初期化します。
# また、モデルをXLAにコンパイルします（初回は数分かかります）。
if model_name.startswith('Mixer'):
  model = models.MlpMixer(num_classes=num_classes, **model_config)
else:
  model = models.VisionTransformer(num_classes=num_classes, **model_config)
variables = jax.jit(lambda: model.init(
    jax.random.PRNGKey(0),
    # 初期化用バッチの「num_local_devices」ディメンションを破棄する。
    batch[0][:1],
    train=False,
), backend='cpu')()

# pretrainedチェックポイントのロードと変換。
# この作業では、実際に事前学習したモデルの結果をロードしますが、同時に
# パラメータを少し変更します。例えば、最終層の変更や、位置埋め込みのサイズ変更など
# 位置エンベッディングを変更します。
# 詳細については、コードと論文のメソッドを参照してください。
params = checkpoint.load_pretrained(
    pretrained_path=f'{model_name}.npz',
    init_params=variables['params'],
    model_config=model_config
)

total_steps = 1 #trainデータの数＝total_steps*Batchとなるように設定する。
warmup_steps = 5
decay_type = 'cosine'
grad_norm_clip = 1
accum_steps = 1789 #Batchと一緒に変更してね
base_lr = 0.03

# Check out train.make_update_fn in the editor on the right side for details.
lr_fn = utils.create_learning_rate_schedule(total_steps, base_lr, decay_type, warmup_steps)
update_fn_repl = train.make_update_fn(
    apply_fn=model.apply, accum_steps=accum_steps, lr_fn=lr_fn)
# We use a momentum optimizer that uses half precision for state to save
# memory. It als implements the gradient clipping.
opt = momentum_clip.Optimizer(grad_norm_clip=grad_norm_clip).create(params)
opt_repl = flax.jax_utils.replicate(opt)

#訓練後のパラメーターはopt_replに格納されるようです。

# Initialize PRNGs for dropout.

update_rng_repl = flax.jax_utils.replicate(jax.random.PRNGKey(0))

batch[0].shape[0]

import tqdm

losses = []
lrs = []
# Completes in ~20 min on the TPU runtime.
for step, batch in zip(
    tqdm.trange(1, total_steps + 1),
    ds.as_numpy_iterator(),
):
  batch_dict = {
      'image':np.array([batch[0]]),
      'label':np.array([batch[1]])
  }

  opt_repl, loss_repl, update_rng_repl = update_fn_repl(
      opt_repl, flax.jax_utils.replicate(step), batch_dict, update_rng_repl)
  losses.append(loss_repl[0])
  lrs.append(lr_fn(step))

plt.plot(losses)
plt.figure()
plt.plot(lrs)

#batch['image'].shape

 #タプルのインデックスは、strではなく、整数またはスライスでなければなりません。

"""#テストデータのロード"""

import requests

test_image_paths = list(test_data_tmp['primaryImage'])
test_image_medium = list(test_data_tmp["Medium"])
paths_test_tmp= []
medium_test_tmp = []

cnt = 0
for i in range(len(test_data_tmp)):
  test_image_paths[i] = test_image_paths[i].replace(' ', '%20')
  res = requests.get(test_image_paths[i])
  if res.status_code != 404:
    paths_test_tmp.append(test_image_paths[i])
    medium_test_tmp.append(test_image_medium[i])
  else:
    cnt += 1

test_image_paths = paths_test_tmp
test_image_medium = medium_test_tmp
    
image_count2 = len(test_image_paths)
print(image_count2, cnt)
print(image_count2+cnt)

test_data = pd.DataFrame()
test_data["primaryImage"]  = test_image_paths
test_data["Medium"] = test_image_medium
test_data

label_names_test = sorted(list(set([item for item in test_data['Medium']])))#重複なしに作者名を英語でソート
label_to_index_pre_test = dict((index,name) for index,name in enumerate(label_names_test))#辞書の形にナンバー付け
df_test = pd.DataFrame.from_dict(label_to_index_pre_test, orient='index')
df_test = df_test.reset_index()
df_test = df_test.set_axis(['label', 'Medium'], axis=1)#pd形
all_image_labels_test=[]
for i in range(len(test_data)):
  all_image_labels_test.append(int(df_test[df_test['Medium'] == test_data.loc[i]['Medium']]['label']))#all_image_labels_testは作者ラベルの羅列
all_image_labels_test_i = [int(s) for s in all_image_labels_test]
n_labels_test = len(np.unique(all_image_labels_test_i))#10

# test_image_paths = list(test_data['primaryImage'])#データセットパス.jpg

# #NotFoundを除去するコードを挿入
# memo = []
# for i in range(778):
#   test_image_paths[i] = test_image_paths[i].replace(' ', '%20')
#   if test_image_paths[i] == 'https://images.metmuseum.org/CRDImages/ep/original/DT2628.jpg':
#     memo.append(i)
#   elif  test_image_paths[i] == 'https://images.metmuseum.org/CRDImages/ad/original/DP-19092-001.jpg':
#     memo.append(i)
#   elif test_image_paths[i] == 'https://images.metmuseum.org/CRDImages/ad/original/DP-19092-001.jpg':
#     memo.append(i)
# #967行目のデータがNotFoundだったため消去
# #train_data.drop(memo)

# memo = sorted(memo, reverse=True)
# for i in range(len(memo)):
#   test_image_paths.pop(memo[i])


#image_count2 = len(test_image_paths)

print(memo)

len(test_image_paths)

image_count2

from tqdm.notebook import tqdm
for i in tqdm(test_image_paths):
  create_file(i)

data_root = pathlib.Path('/root/.keras/datasets/')
all_image_paths = sorted(list(sorted(data_root.glob('?.jpg'))))+sorted(list(sorted(data_root.glob('??.jpg'))))+sorted(list(sorted(data_root.glob('???.jpg'))))
test_image_paths = [str(path) for path in all_image_paths][image_count:]
test_image_paths_o = np.eye(n_labels_test)[all_image_labels_test_i] 

path_ds_test = tf.data.Dataset.from_tensor_slices(test_image_paths)
image_ds_test = path_ds_test.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)

#image_ds_testの確認
plt.figure(figsize=(8,8))
for n,image in enumerate(image_ds_test.take(4)):
 plt.subplot(2,2,n+1)
 plt.imshow(image)
 plt.grid(False)
 plt.xticks([])
 plt.yticks([])
 plt.show()

BATCH_SIZE = 5
ds_test = image_ds_test.batch(BATCH_SIZE)
ds_test = ds_test.prefetch(buffer_size=AUTOTUNE)

# Then map the call to our model's forward pass onto all available devices.
#そして、モデルのフォワードパスへの呼び出しを、利用可能なすべてのデバイスにマッピングします。
vit_apply_repl = jax.pmap(lambda params, inputs: model.apply(
    dict(params=params), inputs, train=False))

"""#テストデータの画像分類"""

import tqdm

"""#関数変更点"""

steps = image_count2 // BATCH_SIZE
for i, batch in zip(tqdm.notebook.trange(steps), ds_test.as_numpy_iterator()):
    if i == 0:
        predicted = vit_apply_repl(opt_repl.target, batch[np.newaxis, :])
        predicted = flax.nn.softmax(predicted)
        predict_prob = predicted[0]
    else:
        predicted = vit_apply_repl(opt_repl.target, batch[np.newaxis, :])
        predicted = flax.nn.softmax(predicted)
        predict_prob = np.append(predict_prob, predicted[0], axis=0)

submit_file = pd.DataFrame(predict_prob)
submit_file.index = [path.replace("test/", "") for path in test_image_paths]
submit_file.to_csv("result_file.csv", header=False)

submit_file.columns = label_names

submit_file

results = pd.DataFrame(submit_file.idxmax(axis=1))
results

results = pd.DataFrame(results)
results.index = [path.replace("test/", "") for path in test_image_paths]
results.to_csv("results.csv", header=False)

c=0
for i in range(image_count2):
  if results.iloc[i][0] == test_data['Medium'][i]:
    c+=1

print(c)

accuracy = c / image_count2
accuracy

"""#モデルの保存"""

!mkdir -p /content/data /content/model

